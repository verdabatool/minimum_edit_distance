{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Minimum Edit Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c80fe806",
      "metadata": {},
      "source": [
        "![MED_Cover](cover_images/MED_Cover.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Setting up the foundation\n",
        "\n",
        "The **Minimum Edit Distance** (MED) is the minimum number of edits (insertions, deletions, substitutions) needed to transform one string into another. This is often implemented via dynamic programming (you can learn more about the algorithm in the lecture slides and notes).\n",
        "\n",
        "### Task\n",
        "1. Implement a `min_edit_distance` function using dynamic programming.\n",
        "2. Show the DP matrix for the following test words: kitten → sitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae26911",
      "metadata": {},
      "outputs": [],
      "source": [
        "def min_edit_distance(word1: str, word2: str, insertion_cost=1, deletion_cost=1, substitution_cost=1, verbose=False):\n",
        "    m, n = len(word1), len(word2)\n",
        "    \n",
        "    # Initializing DP matrix (size: (m+1) x (n+1))\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "    \n",
        "    # Base cases: transforming from empty string\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i * deletion_cost\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j * insertion_cost\n",
        "    \n",
        "    # Filling the DP matrix\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if word1[i - 1] == word2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]  # No cost if characters match\n",
        "            else:\n",
        "                dp[i][j] = min(\n",
        "                    dp[i - 1][j] + deletion_cost,     # Deletion\n",
        "                    dp[i][j - 1] + insertion_cost,    # Insertion\n",
        "                    dp[i - 1][j - 1] + substitution_cost  # Substitution\n",
        "                )\n",
        "    \n",
        "    # Printing DP matrix if verbose\n",
        "    if verbose:\n",
        "        print(\"DP Matrix:\")\n",
        "        print(\"    \" + \"  \".join([\" \"] + list(word2)))\n",
        "        for i, row in enumerate(dp):\n",
        "            if i == 0:\n",
        "                prefix = \" \"\n",
        "            else:\n",
        "                prefix = word1[i-1]\n",
        "            print(prefix, row)\n",
        "    \n",
        "    return dp[m][n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "44b36f82",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Minimum Edit Distance: 3\n"
          ]
        }
      ],
      "source": [
        "distance = min_edit_distance(\"kitten\", \"sitting\", verbose=False)\n",
        "print(\"\\nMinimum Edit Distance:\", distance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b92c9a",
      "metadata": {},
      "source": [
        "#### Reflective Question\n",
        "\n",
        "**Why is minimum edit distance a good measure of similarity? When might it fail?**  \n",
        "**Answer:**  \n",
        "MED is a good measure for surface-level similarity as it directly measures how many changes are required to convert one string into another. This helpful in techniques such as spell checking, DNA sequence alignment etc. However, it is unable to capture deep semantic level similarity. For example, doog and puppy require 4 edits but are very similar semantically. I is also very sensitive to the word order. e-g. eat food and food eat has two edits but humans perceive them very similar. It doesn't have any account of the context as it looks at characters only and not grammar or meaning.  \n",
        "Hence, MED is a good measure for surface level similarity but is not recommended for deep semantic level similarity due to above limitations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Weighted Typo Mystery\n",
        "\n",
        "In real life, not all typos are equal. Common mistakes, like swapping adjacent letters, should be \"cheaper\" than rare mistakes.\n",
        "\n",
        "For example, on your keyboard:\n",
        "- Substituting `q` ↔ `w` would cost 0.5, as they're next to each other\n",
        "\n",
        "- Substituting `q` ↔ `b` would cost 2.0 as they're far away from each other\n",
        "\n",
        "### Task\n",
        "1. Extend your function to support a **custom cost matrix**.\n",
        "    - Cost of 0.5 for adjacent characters and 2.0 for non-adjacent characters\n",
        "2. Use it to compute the distance between words with weighted costs.\n",
        "    - You have been given a helper function `are_adjacent(c1, c2)` which returns True if both c1 and c2 are next to each other on the keyboard, and False otherwise.\n",
        "3. Compare results between standard MED and weighted MED for sample pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6926037",
      "metadata": {},
      "outputs": [],
      "source": [
        "def are_adjacent(c1: str, c2: str) -> bool:\n",
        "    # QWERTY keyboard layout as a 2D matrix\n",
        "    keyboard = [\n",
        "        ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p'],\n",
        "        ['a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l'],\n",
        "        ['z', 'x', 'c', 'v', 'b', 'n', 'm']\n",
        "    ]\n",
        "\n",
        "    # Function to find position of a character in the keyboard matrix\n",
        "    def find_position(char):\n",
        "        char = char.lower()\n",
        "        for i, row in enumerate(keyboard):\n",
        "            if char in row:\n",
        "                return (i, row.index(char))\n",
        "        return None\n",
        "\n",
        "    pos1 = find_position(c1)\n",
        "    pos2 = find_position(c2)\n",
        "\n",
        "    if not pos1 or not pos2:\n",
        "        return False  # character not on the keyboard\n",
        "\n",
        "    r1, c1 = pos1\n",
        "    r2, c2 = pos2\n",
        "\n",
        "    # Checking adjacency: max distance of 1 in both row and column\n",
        "    return abs(r1 - r2) <= 1 and abs(c1 - c2) <= 1 and pos1 != pos2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_min_edit_distance(word1: str, word2: str, insertion_cost=1, deletion_cost=1, verbose=False):\n",
        "    m, n = len(word1), len(word2)\n",
        "    \n",
        "    # Initializing DP matrix\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "    \n",
        "    # Base cases\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i * deletion_cost\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j * insertion_cost\n",
        "    \n",
        "    # Filling DP matrix\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if word1[i - 1] == word2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]  # No cost\n",
        "            else:\n",
        "                # Weighted substitution cost\n",
        "                if are_adjacent(word1[i - 1], word2[j - 1]):\n",
        "                    sub_cost = 0.5\n",
        "                else:\n",
        "                    sub_cost = 2.0\n",
        "                dp[i][j] = min(\n",
        "                    dp[i - 1][j] + deletion_cost,   # Deletion\n",
        "                    dp[i][j - 1] + insertion_cost,  # Insertion\n",
        "                    dp[i - 1][j - 1] + sub_cost     # Substitution\n",
        "                )\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"Weighted DP Matrix:\")\n",
        "        print(\"    \" + \"  \".join([\" \"] + list(word2)))\n",
        "        for i, row in enumerate(dp):\n",
        "            if i == 0:\n",
        "                prefix = \" \"\n",
        "            else:\n",
        "                prefix = word1[i-1]\n",
        "            print(prefix, row)\n",
        "    \n",
        "    return dp[m][n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2977622c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard MED (kitten → sitting): 3\n",
            "Weighted MED (kitten → sitting): 5\n",
            "Standard MED (q → w): 1\n",
            "Weighted MED (q → w): 0.5\n",
            "Standard MED (q → b): 1\n",
            "Weighted MED (q → b): 2\n"
          ]
        }
      ],
      "source": [
        "# Standard MED\n",
        "print(\"Standard MED (kitten → sitting):\", min_edit_distance(\"kitten\", \"sitting\"))\n",
        "\n",
        "# Weighted MED\n",
        "print(\"Weighted MED (kitten → sitting):\", weighted_min_edit_distance(\"kitten\", \"sitting\"))\n",
        "\n",
        "# Close typo (q → w, adjacent keys)\n",
        "print(\"Standard MED (q → w):\", min_edit_distance(\"q\", \"w\"))\n",
        "print(\"Weighted MED (q → w):\", weighted_min_edit_distance(\"q\", \"w\"))\n",
        "\n",
        "# Distant typo (q → b, far keys)\n",
        "print(\"Standard MED (q → b):\", min_edit_distance(\"q\", \"b\"))\n",
        "print(\"Weighted MED (q → b):\", weighted_min_edit_distance(\"q\", \"b\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: The Spell-Crime Case\n",
        "\n",
        "Your detective agency just got a request: a manuscript full of errors.\n",
        "The task: for each suspicious word, suggest the **top 3 candidate corrections** from a given dictionary, ranked by minimum edit distance.\n",
        "\n",
        "### Task\n",
        "1. Implement a function `suggest_corrections(word, dictionary, top_n=3)`.\n",
        "2. Use your MED function (both standard and weighted) to generate corrections.\n",
        "3. Analyze how the results differ depending on the cost function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for Standard MED:\n",
            "[('spelling', 1), ('selling', 2), ('smelling', 2)]\n",
            "\n",
            "Results for Weighted MED:\n",
            "[('spelling', 1), ('spring', 1.5), ('selling', 2)]\n"
          ]
        }
      ],
      "source": [
        "def suggest_corrections(word, dictionary, weighted=False, top_n=3):\n",
        "    results = []\n",
        "\n",
        "    for candidate in dictionary:\n",
        "        if weighted:\n",
        "            dist = weighted_min_edit_distance(word, candidate)\n",
        "        else:\n",
        "            dist = min_edit_distance(word, candidate)\n",
        "        results.append((candidate, dist))\n",
        "    \n",
        "    # Sorting by distance (smallest first), then alphabetically\n",
        "    results.sort(key=lambda x: (x[1], x[0]))\n",
        "    \n",
        "    return results[:top_n]\n",
        "\n",
        "\n",
        "dictionary = [\"spelling\", \"selling\", \"spring\", \"smelling\"]\n",
        "print(\"Results for Standard MED:\")\n",
        "print(suggest_corrections(\"speling\", dictionary, weighted=False))\n",
        "\n",
        "print(\"\\nResults for Weighted MED:\")\n",
        "print(suggest_corrections(\"speling\", dictionary, weighted=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "227f2bcb",
      "metadata": {},
      "source": [
        "## Reflective Question  \n",
        "**Does weighted MED reveal more insight on the similarity between two words than standard MED? If so, then explain how.**\n",
        "\n",
        "Answer:\n",
        "Yes, weighted MED provides more insight than standard MED because it accounts for how realistic certain errors are. For example, substituting adjacent keys (like t → y) costs less than distant ones (like t → c). This makes the measure more aligned with real typing mistakes, leading to more meaningful word similarity judgments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Language Identification\n",
        "\n",
        "A linguistic detective agency has received a single, typo-ridden word from a spy's message. They suspect the word reveals the spy's native language. Different languages have different common character sequences and typo patterns. Your task is to use MED to identify the likely language of origin.\n",
        "\n",
        "You will identify a language by calculating the average MED of the typoed word against a corpus of known words for each language. The language with the lower average MED is the most likely candidate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average MED (English): 4.00\n",
            "Average MED (German): 4.80\n",
            "Likely Language: English\n"
          ]
        }
      ],
      "source": [
        "english_corpus = [\"apple\", \"banana\", \"cat\", \"dog\", \"house\"]\n",
        "german_corpus = [\"apfel\", \"banane\", \"katze\", \"hund\", \"haus\"]\n",
        "typo_word = \"dohg\"\n",
        "\n",
        "def identify_language(typo_word, english_corpus, german_corpus):\n",
        "    # Helper to compute average MED\n",
        "    def average_med(word, corpus):\n",
        "        total = 0\n",
        "        for w in corpus:\n",
        "            total += min_edit_distance(word, w)  # reusing MED from Part 1\n",
        "        return total / len(corpus)\n",
        "\n",
        "    eng_score = average_med(typo_word, english_corpus)\n",
        "    ger_score = average_med(typo_word, german_corpus)\n",
        "    print(f\"Average MED (English): {eng_score:.2f}\")\n",
        "    print(f\"Average MED (German): {ger_score:.2f}\")\n",
        "    if eng_score < ger_score:\n",
        "        return \"English\"\n",
        "    elif ger_score < eng_score:\n",
        "        return \"German\"\n",
        "    else:\n",
        "        return \"Tie\"\n",
        "print(\"Likely Language:\", identify_language(typo_word, english_corpus, german_corpus))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (nlp_pa1)",
      "language": "python",
      "name": "nlp_pa1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
